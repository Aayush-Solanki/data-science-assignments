{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aafcb9ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          Unnamed: 0 Unnamed: 1  \\\n",
      "0  Source: Based upon real business data; company...        NaN   \n",
      "1             (c) 2016 Galit Shmueli and Peter Bruce        NaN   \n",
      "2                                                NaN        NaN   \n",
      "3                                                NaN        NaN   \n",
      "4                                         Field Name  Data Type   \n",
      "\n",
      "        Unnamed: 2                         Unnamed: 3   Unnamed: 4  \n",
      "0              NaN                                NaN          NaN  \n",
      "1              NaN                                NaN          NaN  \n",
      "2              NaN                                NaN          NaN  \n",
      "3              NaN                                NaN          NaN  \n",
      "4  Max Data Length  Raw Data or Telcom Created Field?  Description  \n",
      "Unnamed: 0     6\n",
      "Unnamed: 1     9\n",
      "Unnamed: 2    16\n",
      "Unnamed: 3     9\n",
      "Unnamed: 4     4\n",
      "dtype: int64\n",
      "                                               Unnamed: 0 Unnamed: 1  \\\n",
      "count                                                  16         13   \n",
      "unique                                                 16          3   \n",
      "top     Source: Based upon real business data; company...     NUMBER   \n",
      "freq                                                    1          9   \n",
      "\n",
      "        Unnamed: 2 Unnamed: 3   Unnamed: 4  \n",
      "count            6         13           18  \n",
      "unique           3          3           18  \n",
      "top              1        Raw  Description  \n",
      "freq             3          9            1  \n"
     ]
    }
   ],
   "source": [
    "file_path = r\"C:\\Users\\Owner\\OneDrive\\Desktop\\data science assingment\\assignments\\clustering\\EastWestAirlines.xlsx\"\n",
    "data_df = pd.read_excel(file_path, skiprows=4)\n",
    "\n",
    "\n",
    "print(data_df.head())\n",
    "\n",
    "\n",
    "print(data_df.isnull().sum())\n",
    "\n",
    "\n",
    "print(data_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8bae9158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['East-West Airlines is trying to learn more about its customers.  Key issues are their',\n",
      "       'Unnamed: 1', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['Unnamed: 0'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m airlines_df\u001b[38;5;241m.\u001b[39mdropna(inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Drop any unnecessary columns\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m airlines_df\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnnamed: 0\u001b[39m\u001b[38;5;124m'\u001b[39m], inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Convert non-numeric columns to numeric if needed\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# For example, if 'Award' column is categorical, convert it to numeric using LabelEncoder\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Standardize the data\u001b[39;00m\n\u001b[0;32m     28\u001b[0m scaler \u001b[38;5;241m=\u001b[39m StandardScaler()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\frame.py:5581\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[0;32m   5434\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5435\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5442\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   5443\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5444\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5445\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5446\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5579\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5580\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mdrop(\n\u001b[0;32m   5582\u001b[0m         labels\u001b[38;5;241m=\u001b[39mlabels,\n\u001b[0;32m   5583\u001b[0m         axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   5584\u001b[0m         index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[0;32m   5585\u001b[0m         columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m   5586\u001b[0m         level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[0;32m   5587\u001b[0m         inplace\u001b[38;5;241m=\u001b[39minplace,\n\u001b[0;32m   5588\u001b[0m         errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m   5589\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\generic.py:4788\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4786\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4788\u001b[0m         obj \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_drop_axis(labels, axis, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4790\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4791\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\generic.py:4830\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4828\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4829\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4830\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4831\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4833\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4834\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:7070\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   7068\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   7069\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 7070\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   7071\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   7072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['Unnamed: 0'] not found in axis\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import AgglomerativeClustering, KMeans, DBSCAN\n",
    "\n",
    "\n",
    "\n",
    "dataset_file = r\"C:\\Users\\Owner\\OneDrive\\Desktop\\data science assingment\\assignments\\clustering\\EastWestAirlines.xlsx\"  \n",
    "airlines_df = pd.read_excel(dataset_file)\n",
    "\n",
    "\n",
    "print(airlines_df.columns)\n",
    "\n",
    "\n",
    "\n",
    "airlines_df.dropna(inplace=True)\n",
    "\n",
    "\n",
    "airlines_df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(airlines_df)\n",
    "\n",
    "\n",
    "def hierarchical_clustering(data, n_clusters_range):\n",
    "    sil_scores = []\n",
    "    for n_clusters in n_clusters_range:\n",
    "        hierarchical_cluster = AgglomerativeClustering(n_clusters=n_clusters)\n",
    "        hierarchical_cluster.fit(data)\n",
    "        sil_score = silhouette_score(data, hierarchical_cluster.labels_)\n",
    "        sil_scores.append(sil_score)\n",
    "\n",
    "    plt.plot(n_clusters_range, sil_scores, marker='o')\n",
    "    plt.xlabel('Number of Clusters')\n",
    "    plt.ylabel('Silhouette Score')\n",
    "    plt.title('Silhouette Score for Hierarchical Clustering')\n",
    "    plt.show()\n",
    "\n",
    "hierarchical_clustering(scaled_data, range(2, 11))\n",
    "\n",
    "\n",
    "def kmeans_clustering(data, n_clusters_range):\n",
    "    inertias = []\n",
    "    sil_scores = []\n",
    "    for n_clusters in n_clusters_range:\n",
    "        kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "        kmeans.fit(data)\n",
    "        inertias.append(kmeans.inertia_)\n",
    "        sil_score = silhouette_score(data, kmeans.labels_)\n",
    "        sil_scores.append(sil_score)\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(n_clusters_range, inertias, marker='o')\n",
    "    plt.xlabel('Number of Clusters')\n",
    "    plt.ylabel('Inertia')\n",
    "    plt.title('Elbow Plot for K-means Clustering')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(n_clusters_range, sil_scores, marker='o')\n",
    "    plt.xlabel('Number of Clusters')\n",
    "    plt.ylabel('Silhouette Score')\n",
    "    plt.title('Silhouette Score for K-means Clustering')\n",
    "    plt.show()\n",
    "\n",
    "kmeans_clustering(scaled_data, range(2, 11))\n",
    "\n",
    "\n",
    "def dbscan_clustering(data, eps_range, min_samples_range):\n",
    "    for eps in eps_range:\n",
    "        for min_samples in min_samples_range:\n",
    "            dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "            dbscan.fit(data)\n",
    "            n_clusters = len(set(dbscan.labels_)) - (1 if -1 in dbscan.labels_ else 0)\n",
    "            print(f\"EPS={eps}, Min Samples={min_samples}, Number of Clusters={n_clusters}\")\n",
    "\n",
    "eps_values = [0.1, 0.5, 1.0]\n",
    "min_samples_values = [5, 10, 15]\n",
    "dbscan_clustering(scaled_data, eps_values, min_samples_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82ab1a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IN this data set their is some problem this dataset file is notworking properly jupyter notebook is reading that file  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261d77dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
